# SPDX-FileCopyrightText: Copyright (c) 2024-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

import base64
import logging
from pathlib import Path
from typing import Optional, Union

import aiofiles
import aiohttp
from pydantic import Field, BaseModel, field_validator

from nat.builder.builder import Builder
from nat.builder.function_info import FunctionInfo
from nat.cli.register_workflow import register_function
from nat.data_models.function import FunctionBaseConfig

logger = logging.getLogger(__name__)


class RoadSceneAnalyzerConfig(FunctionBaseConfig, name="road_scene_analyzer"):
    """
    è‡ªå®šä¹‰å‡½æ•°é…ç½®ï¼šè·¯ä¾§åœºæ™¯å›¾ç‰‡åˆ†æå™¨
    æ”¯æŒæœ¬åœ°æ–‡ä»¶ä¸Šä¼ ã€URLä¸Šä¼ å’ŒBase64ç¼–ç çš„å›¾ç‰‡åˆ†æ
    """
    llm_name: str = Field(description="LLMåç§°ï¼Œåº”è¯¥æŒ‡å‘æ”¯æŒè§†è§‰çš„æ¨¡å‹å¦‚qwen-vl-plus")
    max_image_size_mb: int = Field(default=20, description="æœ€å¤§å›¾ç‰‡å¤§å°ï¼ˆMBï¼‰")
    timeout_seconds: int = Field(default=30, description="ç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")


class TrafficInfoStorageConfig(FunctionBaseConfig, name="traffic_info_storage"):
    """
    è‡ªå®šä¹‰å‡½æ•°é…ç½®ï¼šäº¤é€šä¿¡æ¯å­˜å‚¨
    å­˜å‚¨åˆ†æåçš„äº¤é€šä¿¡æ¯å’Œä½ç½®æ—¶é—´æ•°æ®
    """
    storage_path: str = Field(default="./data/traffic_info", description="æ•°æ®å­˜å‚¨è·¯å¾„")


class TrafficInfoQueryConfig(FunctionBaseConfig, name="traffic_info_query"):
    """
    è‡ªå®šä¹‰å‡½æ•°é…ç½®ï¼šäº¤é€šä¿¡æ¯æŸ¥è¯¢
    æŸ¥è¯¢ç‰¹å®šä½ç½®å’Œæ—¶é—´èŒƒå›´å†…çš„äº¤é€šä¿¡æ¯
    """
    storage_path: str = Field(default="./data/traffic_info", description="æ•°æ®å­˜å‚¨è·¯å¾„")


async def _load_image_data(image_source: str) -> tuple[bytes, str]:
    """
    åŠ è½½å›¾ç‰‡æ•°æ®ï¼Œæ”¯æŒæœ¬åœ°è·¯å¾„ã€URLå’ŒBase64ç¼–ç 
    è¿”å› (image_bytes, mime_type)
    """
    # æ£€æŸ¥æ˜¯å¦ä¸ºBase64ç¼–ç 
    if image_source.startswith("data:"):
        # å¤„ç†Data URIæ ¼å¼
        parts = image_source.split(";")
        mime_type = parts[0].replace("data:", "")
        if "base64," in parts[1]:
            data = parts[1].split("base64,")[1]
        else:
            data = parts[1]
        return base64.b64decode(data), mime_type
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºBase64å­—ç¬¦ä¸²ï¼ˆæ— Data URIå‰ç¼€ï¼‰
    if not image_source.startswith(("http://", "https://", "/")):
        try:
            return base64.b64decode(image_source), "image/jpeg"
        except Exception:
            pass
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
    if Path(image_source).exists():
        async with aiofiles.open(image_source, "rb") as f:
            data = await f.read()
        
        # æ¨æ–­MIMEç±»å‹
        suffix = Path(image_source).suffix.lower()
        mime_types = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".gif": "image/gif",
            ".webp": "image/webp",
        }
        mime_type = mime_types.get(suffix, "image/jpeg")
        return data, mime_type
    
    # å¦åˆ™å°è¯•ä»URLä¸‹è½½
    if image_source.startswith(("http://", "https://")):
        async with aiohttp.ClientSession() as session:
            async with session.get(image_source, timeout=aiohttp.ClientTimeout(total=30)) as resp:
                if resp.status != 200:
                    raise ValueError(f"æ— æ³•ä¸‹è½½å›¾ç‰‡: HTTP {resp.status}")
                data = await resp.read()
                
                # ä»Content-Typeå¤´è·å–MIMEç±»å‹
                content_type = resp.headers.get("Content-Type", "image/jpeg")
                mime_type = content_type.split(";")[0]
                return data, mime_type
    
    raise ValueError(f"æ— æ³•è¯†åˆ«å›¾ç‰‡æ¥æº: {image_source}")


@register_function(config_type=RoadSceneAnalyzerConfig)
async def road_scene_analyzer(config: RoadSceneAnalyzerConfig, builder: Builder):
    """
    è·¯ä¾§åœºæ™¯å›¾ç‰‡åˆ†æå‡½æ•°
    æ”¯æŒæœ¬åœ°ä¸Šä¼ ã€URLä¸Šä¼ ï¼ŒåŸºäºåƒé—®å›¾åƒç†è§£æ¨¡å‹åˆ†æåœºæ™¯
    """
    class RoadSceneAnalysisInput(BaseModel):
        image_source: str = Field(
            description="å›¾ç‰‡æ¥æºï¼šæœ¬åœ°è·¯å¾„ã€URLæˆ–Base64ç¼–ç "
        )
        location: Optional[str] = Field(
            default=None,
            description="ä½ç½®ä¿¡æ¯ï¼Œæ ¼å¼ï¼šç»åº¦,çº¬åº¦ æˆ– åœ°å€æè¿°"
        )
        device_id: Optional[str] = Field(
            default=None,
            description="è®¾å¤‡IDï¼Œç”¨äºæ ‡è¯†ä¸Šä¼ è€…"
        )
        analysis_type: str = Field(
            default="all",
            description="åˆ†æç±»å‹ï¼štraffic(äº¤é€š), environment(ç¯å¢ƒ), weather(å¤©æ°”), all(å…¨éƒ¨)"
        )
    
    class RoadSceneAnalysisOutput(BaseModel):
        success: bool = Field(description="åˆ†ææ˜¯å¦æˆåŠŸ")
        scene_description: str = Field(description="åœºæ™¯æè¿°")
        traffic_info: dict = Field(description="äº¤é€šä¿¡æ¯")
        environment_info: dict = Field(description="ç¯å¢ƒä¿¡æ¯")
        weather_info: dict = Field(description="å¤©æ°”ä¿¡æ¯")
        timestamp: str = Field(description="åˆ†ææ—¶é—´æˆ³")
        location: Optional[str] = Field(description="è®°å½•çš„ä½ç½®")
        device_id: Optional[str] = Field(description="è®¾å¤‡ID")
    
    async def _analyze_road_scene(input_data: RoadSceneAnalysisInput) -> RoadSceneAnalysisOutput:
        """åˆ†æè·¯ä¾§åœºæ™¯"""
        from datetime import datetime
        
        # è·å–LLM
        try:
            # ä½¿ç”¨LangChain wrapperä»¥ä¾¿ä½¿ç”¨ainvoke
            llm = await builder.get_llm(llm_name=config.llm_name, wrapper_type="langchain")
        except Exception as e:
            logger.warning(f"æ— æ³•è·å–LLM {config.llm_name}: {e}ï¼Œå°†ä½¿ç”¨ç›´æ¥åˆ†æ")
            llm = None
        
        try:
            # åŠ è½½å›¾ç‰‡
            image_bytes, mime_type = await _load_image_data(input_data.image_source)
            image_base64 = base64.b64encode(image_bytes).decode("utf-8")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            base_prompt = """
            è¯·åˆ†æè¿™å¼ è·¯ä¾§åœºæ™¯å›¾ç‰‡ï¼Œå¹¶è¿”å›ä¸€ä¸ªä¸¥æ ¼çš„JSONæ ¼å¼ç»“æœï¼ˆä¸è¦åŒ…å«markdownä»£ç å—æ ‡è®°ï¼‰ã€‚
            JSONç»“æ„å¦‚ä¸‹ï¼š
            {
                "congestion_level": "è¯„ä¼°æ‹¥å µç­‰çº§ï¼šç•…é€šã€ç¼“è¡Œã€æ‹¥å µã€ä¸¥é‡æ‹¥å µ",
                "traffic_analysis": "è¯¦ç»†çš„äº¤é€šçŠ¶å†µåˆ†æï¼ŒåŒ…æ‹¬é“è·¯é€šç•…åº¦ã€è½¦è¾†æµé‡ã€äº¤é€šæ ‡å¿—ã€äº¤é€šç¯çŠ¶æ€ã€äº‹æ•…ç­‰",
                "environment_analysis": "è¯¦ç»†çš„ç¯å¢ƒä¿¡æ¯åˆ†æï¼ŒåŒ…æ‹¬å»ºç­‘ç‰©ã€è¡—é“è®¾æ–½ã€åœ°æ ‡ã€äººæµã€æ˜¯å¦æœ‰æ‘†æ‘Šç­‰",
                "weather_analysis": "è¯¦ç»†çš„å¤©æ°”æ¡ä»¶åˆ†æï¼ŒåŒ…æ‹¬èƒ½è§åº¦ã€å¤©æ°”çŠ¶å†µã€å…‰ç…§æ¡ä»¶ç­‰",
                "vehicle_count": 0, // ä¼°è®¡çš„æœºåŠ¨è½¦æ€»æ•°ï¼ˆæ•´æ•°ï¼‰
                "vulnerable_count": 0, // ä¼°è®¡çš„è¡Œäººã€è‡ªè¡Œè½¦å’Œæ‘©æ‰˜è½¦æ€»æ•°ï¼ˆæ•´æ•°ï¼‰
                "is_traffic_event": false, // æ˜¯å¦æœ‰äº¤é€šäº‹æ•…ã€ä¸¥é‡æ‹¥å µæˆ–æ–½å·¥ç­‰äº‹ä»¶ï¼ˆå¸ƒå°”å€¼ï¼‰
                "event_summary": "äº‹ä»¶ç®€è¿°ï¼Œæ— äº‹ä»¶åˆ™å¡«None",
                "detections": [ // ä»…å½“æ£€æµ‹åˆ°äº¤é€šäº‹ä»¶ã€è½¦è¾†å¯†é›†(>20)æˆ–äººç¾¤å¯†é›†(>20)æ—¶è¿”å›ï¼Œå¦åˆ™ä¸ºç©ºæ•°ç»„
                    {
                        "label": "ç›®æ ‡ç±»åˆ«(å¦‚car, person, accident)",
                        "box_2d": [ymin, xmin, ymax, xmax], // å½’ä¸€åŒ–åæ ‡ [0-1000]
                        "description": "ç®€çŸ­æè¿°"
                    }
                ],
                "osd_timestamp": "ä»å›¾ç‰‡ä¸­è¯†åˆ«å‡ºçš„æ—¶é—´æˆ³(YYYY-MM-DD HH:MM:SS)ï¼Œå¦‚æœæ— æ³•è¯†åˆ«åˆ™ä¸ºnull"
            }
            """
            
            prompt = base_prompt
            
            # å¦‚æœæœ‰LLMï¼Œä½¿ç”¨LLMè¿›è¡Œåˆ†æ
            if llm:
                try:
                    from langchain_core.messages import HumanMessage
                    import json
                    import re
                    
                    # ä½¿ç”¨OpenAIå…¼å®¹çš„APIæ ¼å¼è°ƒç”¨è§†è§‰æ¨¡å‹
                    response = await llm.ainvoke(
                        input=[
                            HumanMessage(
                                content=[
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:{mime_type};base64,{image_base64}"
                                        }
                                    },
                                    {
                                        "type": "text",
                                        "text": prompt
                                    }
                                ]
                            )
                        ]
                    )
                    
                    raw_content = response.content if hasattr(response, 'content') else str(response)
                    
                    # å°è¯•è§£æJSON
                    try:
                        # ç§»é™¤å¯èƒ½çš„markdownæ ‡è®°
                        cleaned_content = re.sub(r'^```json\s*|\s*```$', '', raw_content.strip(), flags=re.MULTILINE)
                        data = json.loads(cleaned_content)
                        
                        congestion = data.get("congestion_level", "æœªçŸ¥")
                        traffic_text = data.get("traffic_analysis", "æ— äº¤é€šä¿¡æ¯")
                        env_text = data.get("environment_analysis", "æ— ç¯å¢ƒä¿¡æ¯")
                        weather_text = data.get("weather_analysis", "æ— å¤©æ°”ä¿¡æ¯")
                        v_count = data.get("vehicle_count", 0)
                        p_count = data.get("vulnerable_count", 0)
                        is_event = data.get("is_traffic_event", False)
                        event_desc = data.get("event_summary", "None")
                        detections = data.get("detections", [])
                        osd_ts = data.get("osd_timestamp")
                        
                        # ç¡®å®šæ—¶é—´æˆ³
                        final_timestamp = datetime.now().isoformat()
                        if osd_ts and osd_ts != "null":
                            final_timestamp = osd_ts
                        else:
                            # å°è¯•ä»æ–‡ä»¶åè§£æ
                            import re
                            filename_match = re.search(r'(\d{4})(\d{2})(\d{2})_(\d{2})(\d{2})(\d{2})', input_data.image_source)
                            if filename_match:
                                y, m, d, H, M, S = filename_match.groups()
                                final_timestamp = f"{y}-{m}-{d} {H}:{M}:{S}"

                        # æ„å»ºåœºæ™¯æè¿° - ä¼˜åŒ–å‰ç«¯æ˜¾ç¤ºæ•ˆæœ
                        event_status = "ğŸ”´ æœ‰" if is_event else "ğŸŸ¢ æ— "
                        event_detail = f"({event_desc})" if is_event else ""
                        
                        congestion_icon = "ğŸŸ¢"
                        if congestion in ["ç¼“è¡Œ"]: congestion_icon = "ğŸŸ¡"
                        if congestion in ["æ‹¥å µ", "ä¸¥é‡æ‹¥å µ"]: congestion_icon = "ğŸ”´"
                        
                        scene_desc = f"""### ğŸš¦ äº¤é€šè·¯å†µæ¦‚è§ˆ
| æŒ‡æ ‡ | çŠ¶æ€ | è¯¦æƒ… |
| :--- | :--- | :--- |
| **äº¤é€šäº‹ä»¶** | {event_status} | {event_detail} |
| **é€šè¡ŒçŠ¶å†µ** | {congestion_icon} {congestion} | æœºåŠ¨è½¦çº¦ {v_count} è¾† |

### ğŸ“ è¯¦ç»†åˆ†æ
**äº¤é€šçŠ¶å†µ**: {traffic_text}

**ç¯å¢ƒä¿¡æ¯**: {env_text}

**å¤©æ°”æ¡ä»¶**: {weather_text}
"""
                        
                        # å‘Šè­¦é€»è¾‘
                        if is_event or v_count > 20 or p_count > 20:
                            alert_reason = []
                            if is_event: alert_reason.append(f"æ£€æµ‹åˆ°äº¤é€šäº‹ä»¶: {event_desc}")
                            if v_count > 20: alert_reason.append(f"è½¦è¾†å¯†é›† ({v_count}è¾†)")
                            if p_count > 20: alert_reason.append(f"äººç¾¤/éæœºåŠ¨è½¦å¯†é›† ({p_count}ä¸ª)")
                            
                            scene_desc += f"\n\nğŸš¨ **æ³¨æ„**: {', '.join(alert_reason)}"
                            
                            # å¦‚æœæœ‰æ£€æµ‹æ¡†ï¼Œæ·»åŠ åˆ°æè¿°ä¸­ä¾›å‰ç«¯è§£æï¼ˆæš‚æ—¶ä»¥æ–‡æœ¬å½¢å¼ï¼‰
                            if detections:
                                scene_desc += f"\n\n**æ£€æµ‹ç›®æ ‡**: {len(detections)} ä¸ªé‡ç‚¹ç›®æ ‡å·²æ ‡è®°ã€‚"
                                
                                # å°è¯•ç»˜åˆ¶æ£€æµ‹æ¡†
                                try:
                                    import cv2
                                    import numpy as np
                                    
                                    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æ–‡ä»¶è·¯å¾„
                                    if Path(input_data.image_source).exists():
                                        img = cv2.imread(input_data.image_source)
                                        if img is not None:
                                            h, w = img.shape[:2]
                                            
                                            # ç»˜åˆ¶æ¡†
                                            for det in detections:
                                                box = det.get("box_2d")
                                                label = det.get("label", "unknown")
                                                if box and len(box) == 4:
                                                    # å½’ä¸€åŒ–åæ ‡ [ymin, xmin, ymax, xmax] -> åƒç´ åæ ‡
                                                    ymin, xmin, ymax, xmax = box
                                                    pt1 = (int(xmin * w / 1000), int(ymin * h / 1000))
                                                    pt2 = (int(xmax * w / 1000), int(ymax * h / 1000))
                                                    
                                                    # ç»˜åˆ¶çŸ©å½¢
                                                    cv2.rectangle(img, pt1, pt2, (0, 0, 255), 2)
                                                    
                                                    # ç»˜åˆ¶æ ‡ç­¾
                                                    cv2.putText(img, label, (pt1[0], pt1[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                                            
                                            # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
                                            output_path = Path(input_data.image_source).parent / f"annotated_{Path(input_data.image_source).name}"
                                            cv2.imwrite(str(output_path), img)
                                            
                                            # æ·»åŠ åˆ°æè¿°ä¸­
                                            # Convert to base64 for frontend display since local path is not accessible
                                            _, buffer = cv2.imencode('.jpg', img)
                                            img_base64 = base64.b64encode(buffer).decode('utf-8')
                                            scene_desc += f"\n\n![Annotated Image](data:image/jpeg;base64,{img_base64})"
                                            
                                except ImportError:
                                    logger.warning("OpenCV not installed, skipping annotation.")
                                except Exception as e:
                                    logger.warning(f"Failed to draw annotations: {e}")

                        # æ·»åŠ æ—¶é—´æˆ³ä¿¡æ¯åˆ°æè¿°
                        scene_desc += f"\n\n**æ—¶é—´ä¿¡æ¯**:\n- å›¾ç‰‡æ—¶é—´: {final_timestamp}\n- å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                        
                        # æç¤ºAgentè¿›è¡Œå­˜å‚¨
                        scene_desc += "\n\n**SYSTEM NOTE**: Analysis complete. You MUST now call the `traffic_info_storage` tool to save this result."
                        
                        analysis_result = scene_desc
                        
                        # åˆ†ç¦»ä¿¡æ¯
                        traffic_info = {
                            "status": "analyzed", 
                            "details": traffic_text, 
                            "congestion": congestion,
                            "vehicle_count": v_count, 
                            "vulnerable_count": p_count,
                            "event_detected": is_event,
                            "detections": detections
                        }
                        environment_info = {"status": "analyzed", "details": env_text}
                        weather_info = {"status": "analyzed", "details": weather_text}
                        
                    except json.JSONDecodeError:
                        logger.warning(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬: {raw_content[:100]}...")
                        analysis_result = raw_content
                        traffic_info = {"status": "analyzed", "details": raw_content}
                        environment_info = {"status": "analyzed", "details": raw_content}
                        weather_info = {"status": "analyzed", "details": raw_content}
                        final_timestamp = datetime.now().isoformat()

                except Exception as e:
                    logger.warning(f"LLMè°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ")
                    analysis_result = f"å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
                    traffic_info = {}
                    environment_info = {}
                    weather_info = {}
                    final_timestamp = datetime.now().isoformat()
            else:
                analysis_result = f"å·²åŠ è½½å›¾ç‰‡ï¼Œå¤§å°: {len(image_bytes)} å­—èŠ‚ï¼Œç±»å‹: {mime_type}"
                traffic_info = {}
                environment_info = {}
                weather_info = {}
                final_timestamp = datetime.now().isoformat()
            
            return RoadSceneAnalysisOutput(
                success=True,
                scene_description=analysis_result,
                traffic_info=traffic_info,
                environment_info=environment_info,
                weather_info=weather_info,
                timestamp=final_timestamp,
                location=input_data.location,
                device_id=input_data.device_id,
            )
        
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return RoadSceneAnalysisOutput(
                success=False,
                scene_description=f"åˆ†æå¤±è´¥: {str(e)}",
                traffic_info={},
                environment_info={},
                weather_info={},
                timestamp=datetime.now().isoformat(),
                location=input_data.location,
                device_id=input_data.device_id,
            )
    
    yield FunctionInfo.create(
        single_fn=_analyze_road_scene,
        description="åˆ†æè·¯ä¾§åœºæ™¯å›¾ç‰‡ï¼Œè¯†åˆ«äº¤é€šçŠ¶å†µã€ç¯å¢ƒä¿¡æ¯å’Œå¤©æ°”æ¡ä»¶ã€‚æ”¯æŒæœ¬åœ°è·¯å¾„ã€URLå’ŒBase64ç¼–ç çš„å›¾ç‰‡è¾“å…¥ã€‚",
        input_schema=RoadSceneAnalysisInput,
    )


@register_function(config_type=TrafficInfoStorageConfig)
async def traffic_info_storage(config: TrafficInfoStorageConfig, builder: Builder):
    """
    äº¤é€šä¿¡æ¯å­˜å‚¨å‡½æ•°
    å°†åˆ†æçš„äº¤é€šä¿¡æ¯å’Œä½ç½®ã€æ—¶é—´æ•°æ®æŒä¹…åŒ–å­˜å‚¨
    """
    import json
    from typing import Union, Optional
    from pydantic import BaseModel, Field, field_validator
    
    class TrafficInfoInput(BaseModel):
        analysis_result: Union[dict, str] = Field(description="åˆ†æç»“æœ")
        location: str = Field(description="ä½ç½®ä¿¡æ¯ï¼ˆç»åº¦,çº¬åº¦ï¼‰")
        timestamp: str = Field(description="æ—¶é—´æˆ³")
        device_id: Optional[str] = Field(default=None, description="è®¾å¤‡ID")

        @field_validator('analysis_result', mode='before')
        @classmethod
        def parse_analysis_result(cls, v):
            if isinstance(v, str):
                try:
                    return json.loads(v)
                except json.JSONDecodeError:
                    return {"raw_content": v}
            return v

    
    class TrafficInfoStorageOutput(BaseModel):
        success: bool = Field(description="å­˜å‚¨æ˜¯å¦æˆåŠŸ")
        record_id: str = Field(description="è®°å½•ID")
        message: str = Field(description="çŠ¶æ€æ¶ˆæ¯")
    
    # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
    storage_dir = Path(config.storage_path)
    
    async def _store_traffic_info(input_data: TrafficInfoInput) -> TrafficInfoStorageOutput:
        """å­˜å‚¨äº¤é€šä¿¡æ¯"""
        try:
            from datetime import datetime
            import uuid
            
            storage_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆè®°å½•ID
            record_id = str(uuid.uuid4())[:8]
            
            # æ„å»ºè®°å½•æ•°æ®
            record = {
                "id": record_id,
                "location": input_data.location,
                "timestamp": input_data.timestamp,
                "device_id": input_data.device_id or "unknown",
                "analysis_result": input_data.analysis_result,
                "stored_at": datetime.now().isoformat(),
            }
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            record_file = storage_dir / f"{record_id}.json"
            async with aiofiles.open(record_file, "w") as f:
                await f.write(json.dumps(record, ensure_ascii=False, indent=2))
            
            logger.info(f"äº¤é€šä¿¡æ¯å·²å­˜å‚¨: {record_id}")
            
            return TrafficInfoStorageOutput(
                success=True,
                record_id=record_id,
                message=f"äº¤é€šä¿¡æ¯å·²æˆåŠŸå­˜å‚¨ï¼Œè®°å½•ID: {record_id}",
            )
        
        except Exception as e:
            logger.error(f"å­˜å‚¨å¤±è´¥: {e}")
            return TrafficInfoStorageOutput(
                success=False,
                record_id="",
                message=f"å­˜å‚¨å¤±è´¥: {str(e)}",
            )
    
    yield FunctionInfo.create(
        single_fn=_store_traffic_info,
        description="å­˜å‚¨åˆ†æåçš„äº¤é€šä¿¡æ¯å’Œä½ç½®ã€æ—¶é—´æ•°æ®ï¼Œæ”¯æŒå¤šè®¾å¤‡æ•°æ®æ±‡èšã€‚",
        input_schema=TrafficInfoInput,
    )


@register_function(config_type=TrafficInfoQueryConfig)
async def traffic_info_query(config: TrafficInfoQueryConfig, builder: Builder):
    """
    äº¤é€šä¿¡æ¯æŸ¥è¯¢å‡½æ•°
    æŸ¥è¯¢æŒ‡å®šä½ç½®å’Œæ—¶é—´èŒƒå›´å†…çš„äº¤é€šä¿¡æ¯
    """
    import json
    from datetime import datetime, timedelta
    from pydantic import BaseModel, Field
    
    class TrafficInfoQueryInput(BaseModel):
        location: Optional[str] = Field(
            default=None,
            description="æŸ¥è¯¢ä½ç½®ï¼ˆç»åº¦,çº¬åº¦ï¼‰"
        )
        radius_km: float = Field(
            default=5.0,
            description="æŸ¥è¯¢åŠå¾„ï¼ˆå…¬é‡Œï¼‰"
        )
        time_range_hours: int = Field(
            default=24,
            description="æŸ¥è¯¢æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰"
        )
        device_id: Optional[str] = Field(
            default=None,
            description="å¯é€‰ï¼šæŒ‡å®šè®¾å¤‡ID"
        )
    
    class TrafficInfoQueryOutput(BaseModel):
        success: bool = Field(description="æŸ¥è¯¢æ˜¯å¦æˆåŠŸ")
        total_records: int = Field(description="è¿”å›çš„è®°å½•æ•°")
        records: list = Field(description="æŸ¥è¯¢ç»“æœè®°å½•")
        message: str = Field(description="çŠ¶æ€æ¶ˆæ¯")
    
    async def _query_traffic_info(input_data: TrafficInfoQueryInput) -> TrafficInfoQueryOutput:
        """æŸ¥è¯¢äº¤é€šä¿¡æ¯"""
        try:
            storage_dir = Path(config.storage_path)
            
            if not storage_dir.exists():
                return TrafficInfoQueryOutput(
                    success=False,
                    total_records=0,
                    records=[],
                    message="æ•°æ®å­˜å‚¨ç›®å½•ä¸å­˜åœ¨",
                )
            
            # è¯»å–æ‰€æœ‰JSONæ–‡ä»¶
            records = []
            now = datetime.now()
            cutoff_time = now - timedelta(hours=input_data.time_range_hours)
            
            for json_file in storage_dir.glob("*.json"):
                try:
                    async with aiofiles.open(json_file, "r") as f:
                        content = await f.read()
                        record = json.loads(content)
                    
                    # è¿‡æ»¤æ—¶é—´èŒƒå›´
                    record_time = datetime.fromisoformat(record.get("timestamp", ""))
                    if record_time < cutoff_time:
                        continue
                    
                    # è¿‡æ»¤è®¾å¤‡ID
                    if input_data.device_id and record.get("device_id") != input_data.device_id:
                        continue
                    
                    # è¿‡æ»¤ä½ç½®ï¼ˆå¦‚æœæŒ‡å®šï¼‰
                    if input_data.location:
                        record_location = record.get("location", "")
                        if record_location and input_data.location in record_location:
                            records.append(record)
                        elif not record_location:
                            records.append(record)
                    else:
                        records.append(record)
                
                except Exception as e:
                    logger.warning(f"è¯»å–è®°å½•å¤±è´¥ {json_file}: {e}")
            
            return TrafficInfoQueryOutput(
                success=True,
                total_records=len(records),
                records=records[:20],  # é™åˆ¶è¿”å›æ•°é‡
                message=f"æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ° {len(records)} æ¡è®°å½•",
            )
        
        except Exception as e:
            logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
            return TrafficInfoQueryOutput(
                success=False,
                total_records=0,
                records=[],
                message=f"æŸ¥è¯¢å¤±è´¥: {str(e)}",
            )
    
    yield FunctionInfo.create(
        single_fn=_query_traffic_info,
        description="æŸ¥è¯¢ç‰¹å®šä½ç½®å’Œæ—¶é—´èŒƒå›´å†…çš„äº¤é€šä¿¡æ¯ï¼Œæ”¯æŒæŒ‰è®¾å¤‡IDè¿‡æ»¤ã€‚",
        input_schema=TrafficInfoQueryInput,
    )
